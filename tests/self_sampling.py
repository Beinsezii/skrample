import itertools
import math
import random
from dataclasses import replace

import numpy as np
import pytest
import torch
from testing_common import ALL_FAKE_MODELS, ALL_MODELS, ALL_SCHEDULES, ALL_STRUCTURED, ALL_TRANSFROMS, compare_pp

from skrample import scheduling
from skrample.common import SigmaTransform, Step, euler
from skrample.sampling import functional, interface, models, structured, tableaux

type SamplerTestKey = tuple[
    type[structured.StructuredSampler] | type[functional.FunctionalSampler],
    type[scheduling.ScheduleCommon],
    type[models.DiffusionModel],
]

MEASURED_SAMPLERS: list[structured.StructuredSampler | functional.FunctionalSampler] = [
    functional.RKUltra(),
    structured.Adams(),
    structured.SPC(),
]
MEASURED_SCHEDULES: list[scheduling.ScheduleCommon] = [scheduling.Linear(), scheduling.Scaled()]
MEASURED_MODELS: list[models.DiffusionModel] = [
    models.DataModel(),
    models.FlowModel(),
    # models.NoiseModel(),  # / zero
    models.VelocityModel(),
]

MEASURED_STEPS: int = 7
MEASURED_SEED: int = 42


def capture(
    sampler: functional.FunctionalSampler | structured.StructuredSampler,
    schedule: scheduling.ScheduleCommon,
    model: models.DiffusionModel,
) -> list[float]:
    samples: list[float] = []
    random.seed(MEASURED_SEED)
    (
        interface.StructuredFunctionalAdapter(sampler) if isinstance(sampler, structured.StructuredSampler) else sampler
    ).generate_model(
        lambda x, t, s: x - math.sin(t),
        model,
        scheduling.Hyper(schedule),
        random.random,
        MEASURED_STEPS,
        callback=lambda x, i, t, s: samples.append(x),
    )
    return samples


# Auto generated by scripts/sampling_self_measure.py
# fmt: off
MEASURED_SAMPLER_RESULTS: dict[SamplerTestKey, list[float]] = {
    (functional.RKUltra, scheduling.Linear, models.DataModel): [0.5780598392186804, 0.47984288272550235, 0.36652751218728047, 0.44357997939897875, 0.6844909932628795, 0.45987338592721855, 0.5951793487736575],  # noqa: E501
    (functional.RKUltra, scheduling.Linear, models.FlowModel): [0.6541411854539834, 0.6575909905968154, 0.6158597768420465, 0.4742539272590272, 0.2790714207371206, 0.29258072035226296, 0.2630653895681999],  # noqa: E501
    (functional.RKUltra, scheduling.Linear, models.VelocityModel): [0.6124513781869325, 0.5500072845558036, 0.43877573589101987, 0.25002813549326974, 0.06398119136049375, 0.09509440076489664, 0.07264199451746078],  # noqa: E501
    (functional.RKUltra, scheduling.Scaled, models.DataModel): [0.6300931871907277, 0.6176224267634932, 0.6210501754229566, 0.8150691665877265, 1.103791875801471, 0.995328115543478, 1.130634078389917],  # noqa: E501
    (functional.RKUltra, scheduling.Scaled, models.FlowModel): [0.664132347336799, 0.708288578272592, 0.7392745926547724, 0.5874191175220908, 0.3507488804008957, 0.30995208778899164, 0.15800230361404097],  # noqa: E501
    (functional.RKUltra, scheduling.Scaled, models.VelocityModel): [0.6466992262396786, 0.647570542272716, 0.605409393836501, 0.3622010992613355, 0.11677787277282146, 0.16251186182339153, 0.0791635631891336],  # noqa: E501
    (structured.Adams, scheduling.Linear, models.DataModel): [0.5823892132380544, 0.45238300627281497, 0.3893269179260654, 0.22944591590064134, 1.0260936490800747, 0.47614703345685516, 0.6114529963032942],  # noqa: E501
    (structured.Adams, scheduling.Linear, models.FlowModel): [0.652357160411046, 0.6865655116121595, 0.5897498257234484, 0.5503720966982281, 0.12391546260993933, 0.25062205385363334, 0.2240010031899688],  # noqa: E501
    (structured.Adams, scheduling.Linear, models.VelocityModel): [0.6082499371443788, 0.5759467522266517, 0.3996314973648122, 0.34379120213634495, -0.09453883964299331, 0.10484655646602958, 0.08104875615666654],  # noqa: E501
    (structured.Adams, scheduling.Scaled, models.DataModel): [0.6313689484502868, 0.5963880658262994, 0.639788604742546, 0.6078314580200911, 1.390473704962506, 1.0096464267112562, 1.1449523895576952],  # noqa: E501
    (structured.Adams, scheduling.Scaled, models.FlowModel): [0.6634599890325708, 0.7290803151980236, 0.7161887251367887, 0.6899822151363814, 0.12091613842652106, 0.3321052690917803, 0.171353101758476],  # noqa: E501
    (structured.Adams, scheduling.Scaled, models.VelocityModel): [0.6453068566447652, 0.6685746457837283, 0.5608953018885953, 0.5153161547316122, -0.1860890876184754, 0.22329686513620867, 0.12198019090845079],  # noqa: E501
    (structured.SPC, scheduling.Linear, models.DataModel): [0.5823892132380544, 0.4586771307892887, 0.3741928361603825, 0.20446379350926672, 1.0037336805147574, 0.4694307383584173, 0.6047367012048563],  # noqa: E501
    (structured.SPC, scheduling.Linear, models.FlowModel): [0.652357160411046, 0.6839718628050788, 0.6135188719216544, 0.5811791631975856, 0.14133992123072664, 0.2635454619542076, 0.23603296343782088],  # noqa: E501
    (structured.SPC, scheduling.Linear, models.VelocityModel): [0.6082499371443788, 0.5698386190526368, 0.41648461030717204, 0.35170696362721426, -0.11333390686698243, 0.07326063755909841, 0.05382038742020298],  # noqa: E501
    (structured.SPC, scheduling.Scaled, models.DataModel): [0.6313689484502868, 0.5990537809889829, 0.6145638214778157, 0.5604015372368046, 1.3984895479002883, 0.9429774144798273, 1.0782833773262663],  # noqa: E501
    (structured.SPC, scheduling.Scaled, models.FlowModel): [0.6634599890325708, 0.7276754161913265, 0.7441508235578342, 0.7271492552656235, 0.10823100791576633, 0.3722253198512067, 0.19553178254985126],  # noqa: E501
    (structured.SPC, scheduling.Scaled, models.VelocityModel): [0.6453068566447652, 0.6656652764064962, 0.5865910687657327, 0.5294679004438534, -0.24635072058839225, 0.23832813302233824, 0.13256813474580895],  # noqa: E501
}
# fmt: on


@pytest.mark.parametrize(("key"), MEASURED_SAMPLER_RESULTS.keys())
def test_self_samplers(key: SamplerTestKey) -> None:
    smp, sch, md = key
    compare_pp(
        np.asarray(capture(smp(), sch(), md()), dtype=np.float64),
        np.asarray(MEASURED_SAMPLER_RESULTS[key], dtype=np.float64),
        1e-3,
    )


@pytest.mark.parametrize(("model_type", "sigma_transform"), itertools.product(ALL_MODELS, ALL_TRANSFROMS))
def test_model_transforms(model_type: type[models.DiffusionModel], sigma_transform: SigmaTransform) -> None:
    model_transform = model_type()
    sample = 0.8
    output = 0.3
    sigma = 0.2

    x = model_transform.to_x(sample, output, sigma, sigma_transform)
    o = model_transform.from_x(sample, x, sigma, sigma_transform)
    assert abs(output - o) < 1e-12

    sigma_next = 0.05
    for sigma_next in 0.05, 0:  # extra 0 to validate XÌ‚
        snr = euler(
            sample, model_transform.to_x(sample, output, sigma, sigma_transform), sigma, sigma_next, sigma_transform
        )
        df = model_transform.forward(sample, output, sigma, sigma_next, sigma_transform)
        assert abs(snr - df) < 1e-12

        ob = model_transform.backward(sample, df, sigma, sigma_next, sigma_transform)
        assert abs(o - ob) < 1e-12


@pytest.mark.parametrize(
    ("model_from", "model_to", "sigma_transform", "sigma_to"),
    itertools.product(ALL_MODELS, ALL_MODELS + ALL_FAKE_MODELS, ALL_TRANSFROMS, (0.05, 0.0)),
)
def test_model_convert(
    model_from: type[models.DiffusionModel],
    model_to: type[models.DiffusionModel],
    sigma_transform: SigmaTransform,
    sigma_to: float,
) -> None:
    convert = models.ModelConvert(model_from(), model_to())
    sample = 0.8
    output = 0.3
    sigma_from = 0.2

    def model(x: float, t: float, s: float) -> float:
        return output

    x_from = convert.transform_from.forward(
        sample,
        model(sample, sigma_from, sigma_from),
        sigma_from,
        sigma_to,
        sigma_transform,
    )
    x_to = convert.transform_to.forward(
        sample,
        convert.wrap_model_call(model, sigma_transform)(sample, sigma_from, sigma_from),
        sigma_from,
        sigma_to,
        sigma_transform,
    )

    assert abs(x_from - x_to) < 1e-12


@pytest.mark.parametrize(
    ("sampler", "schedule"),
    itertools.product(
        [
            *(cls() for cls in ALL_STRUCTURED),
            *(cls(order=cls.max_order()) for cls in ALL_STRUCTURED if issubclass(cls, structured.StructuredMultistep)),
        ],
        [scheduling.Scaled(), scheduling.FlowShift(scheduling.Linear())],
    ),
)
def test_sampler_generics(sampler: structured.StructuredSampler, schedule: scheduling.ScheduleCommon) -> None:
    eps = 1e-12
    i, o, n = random.random(), random.random(), random.random()
    step = Step.from_int(4, 10)
    prev = [
        structured.SKSamples(
            random.random(),
            random.random(),
            Step((a := random.random()), a * 2),
            random.random(),
            random.random(),
        )
        for _ in range(9)
    ]

    scalar = sampler.sample(i, o, step, models.DataModel(), schedule, n, previous=prev).final

    # Enforce FP64 as that should be equivalent to python scalar
    ndarr = sampler.sample(
        np.array([i], dtype=np.float64),
        np.array([o], dtype=np.float64),
        step,
        models.DataModel(),
        schedule,
        np.array([o], dtype=np.float64),
        previous=prev,  # type: ignore
    ).final.item()  # type: ignore

    tensor = sampler.sample(
        torch.tensor([i], dtype=torch.float64),
        torch.tensor([o], dtype=torch.float64),
        step,
        models.DataModel(),
        schedule,
        torch.tensor([n], dtype=torch.float64),
        previous=prev,  # type: ignore
    ).final.item()  # type: ignore

    assert abs(tensor - scalar) < eps
    assert abs(tensor - ndarr) < eps
    assert abs(scalar - ndarr) < eps


@pytest.mark.parametrize(
    ("sampler"),
    [
        *(
            sampler
            for samplers in (
                (cls(order=o + 1) for o in range(cls.min_order(), cls.max_order()))
                if issubclass(cls, structured.StructuredMultistep)
                else (cls(),)
                for cls in ALL_STRUCTURED
            )
            for sampler in samplers
        ),
        *(structured.UniPC(order=o1, solver=structured.Adams(order=o2)) for o1 in range(1, 4) for o2 in range(1, 4)),
        *(
            structured.SPC(predictor=structured.Adams(order=o1), corrector=structured.Adams(order=o2))
            for o1 in range(1, 4)
            for o2 in range(1, 4)
        ),
    ],
)
def test_require_previous(sampler: structured.StructuredSampler) -> None:
    sample = 1.5
    prediction = 0.5
    previous = tuple(
        structured.SKSamples(n / 2, n * 2, Step.from_int(n, 100), 1 / (n + 1), n * 1.5) for n in range(100)
    )

    a = sampler.sample(
        sample,
        prediction,
        Step.from_int(31, 100),
        models.DataModel(),
        scheduling.Linear(),
        None,
        previous,
    )
    b = sampler.sample(
        sample,
        prediction,
        Step.from_int(31, 100),
        models.DataModel(),
        scheduling.Linear(),
        None,
        previous[len(previous) - sampler.require_previous :],
    )

    assert a == b


@pytest.mark.parametrize(
    ("sampler"),
    [
        *(
            sampler
            for samplers in (
                (cls(add_noise=n) for n in (False, True))
                if issubclass(cls, structured.StructuredStochastic)
                else (cls(),)
                for cls in ALL_STRUCTURED
            )
            for sampler in samplers
        ),
        *(structured.UniPC(solver=structured.DPM(add_noise=n1)) for n1 in (False, True)),
        *(
            structured.SPC(predictor=structured.DPM(add_noise=n1), corrector=structured.DPM(add_noise=n2))
            for n1 in (False, True)
            for n2 in (False, True)
        ),
    ],
)
def test_require_noise(sampler: structured.StructuredSampler) -> None:
    sample = 1.5
    prediction = 0.5
    previous = tuple(
        structured.SKSamples(n / 2, n * 2, Step.from_int(n, 100), 1 / (n + 1), n * 1.5) for n in range(100)
    )
    noise = -0.5

    a = sampler.sample(
        sample,
        prediction,
        Step.from_int(31, 100),
        models.DataModel(),
        scheduling.Linear(),
        noise,
        previous,
    )
    b = sampler.sample(
        sample,
        prediction,
        Step.from_int(31, 100),
        models.DataModel(),
        scheduling.Linear(),
        noise if sampler.require_noise else None,
        previous,
    )

    # Don't compare stored noise since it's expected diff
    b = replace(b, noise=a.noise)

    assert a == b


@pytest.mark.parametrize(
    ("sampler", "schedule", "steps"),
    itertools.product(
        [structured.DPM(o, n) for o in range(1, 4) for n in [False, True]],
        (cls() for cls in ALL_SCHEDULES),
        [1, 3, 4, 9, 512, 999],
    ),
)
def test_functional_adapter(
    sampler: structured.StructuredSampler, schedule: scheduling.ScheduleCommon, steps: int
) -> None:
    def fake_model(x: float, _: float, s: float) -> float:
        return x + math.sin(x) * s

    sample = 1.5
    adapter = interface.StructuredFunctionalAdapter(sampler)
    noise = [random.random() for _ in range(steps)]

    rng = iter(noise)
    model_transform = models.FlowModel()
    sample_f = adapter.sample_model(sample, fake_model, model_transform, schedule, steps, rng=lambda: next(rng))

    rng = iter(noise)
    float_schedule = schedule.schedule(steps)
    sample_s = sample
    previous: list[structured.SKSamples[float]] = []
    for n, (t, s) in enumerate(float_schedule):
        results = sampler.sample(
            sample_s,
            fake_model(sample_s, t, s),
            Step.from_int(n, len(float_schedule)),
            model_transform,
            schedule,
            next(rng),
            previous,
        )
        previous.append(results)
        sample_s = results.final

    assert sample_s == sample_f


@pytest.mark.parametrize(
    ("provider"),
    [
        variant
        for provider in [
            tableaux.RK2,
            tableaux.RK3,
            tableaux.RK4,
            tableaux.RKZ,
            tableaux.RKE2,
            tableaux.RKE3,
            tableaux.RKE5,
        ]
        for variant in provider
    ],
)
def test_tableau_providers(provider: tableaux.TableauProvider) -> None:
    if error := tableaux.validate_tableau(provider.tableau()):
        raise error


def flat_tableau(t: tuple[float | tuple[float | tuple[float | tuple[float, ...], ...], ...], ...]) -> tuple[float, ...]:
    return tuple(z for y in (flat_tableau(x) if isinstance(x, tuple) else (x,) for x in t) for z in y)


def tableau_distance(a: tableaux.Tableau, b: tableaux.Tableau) -> float:
    return abs(np.subtract(flat_tableau(a), flat_tableau(b))).max().item()


def test_rk2_tableau() -> None:
    assert (
        tableau_distance(
            (  # Ralston
                (
                    (0.0, ()),
                    (2 / 3, (2 / 3,)),
                ),
                (1 / 4, 3 / 4),
            ),
            tableaux.rk2_tableau(2 / 3),
        )
        < 1e-20
    )


def test_rk3_tableau() -> None:
    assert (
        tableau_distance(
            (  # Wray
                (
                    (0.0, ()),
                    (8 / 15, (8 / 15,)),
                    (2 / 3, (1 / 4, 5 / 12)),
                ),
                (1 / 4, 0.0, 3 / 4),
            ),
            tableaux.rk3_tableau(8 / 15, 2 / 3),
        )
        < 1e-15
    )


def test_rk4_tableau() -> None:
    assert (
        tableau_distance(
            (  # Eighth
                (
                    (0, ()),
                    (1 / 3, (1 / 3,)),
                    (2 / 3, (-1 / 3, 1)),
                    (1, (1, -1, 1)),
                ),
                (1 / 8, 3 / 8, 3 / 8, 1 / 8),
            ),
            tableaux.rk4_tableau(1 / 3, 2 / 3),
        )
        < 1e-12  # Something like 4x the amount of math as RK3
    )
